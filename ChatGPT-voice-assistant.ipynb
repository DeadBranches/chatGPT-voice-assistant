# %% [markdown]
# ### Text to speech

# %%
!pip3 install --user future==0.18.2
!pip3 install --user --upgrade google-cloud-texttospeech==2.12.3
!pip3 install google-auth
!pip3 install google-auth[pyopenssl]

# %% [markdown]
# ### Speech to text libraries

# %%
# stuff for speech to text
!pip3 install --user git+https://github.com/openai/whisper.git
!pip3 install --user gradio
!pip3 install -q --user ipywidgets
# from speech to text
import whisper
import gradio as gr
import time
import warnings


# %%
# global secret token definition
secret_token = "eyJhbGciOiJkaXIiLCJlbmMiOiJBMjU2R0NNIn0..Wmiwa74JQuSC3ppz.Sbxtkz2ZWN2tErJH2OeASZ3r48fRoNqwJ8zEY1RXHr6upljVbSV_jOiNTYPZkeN_FpQptLjmAab0GTQ8orqyBEA76MKEl0Bo9JtIH8EK5xtESzS84SyMxYvGAoUaUHe7c2aFB4DEq7DYgPb6-oXuyz43BNKZschyjP3toq7_EqrZpbsH2dvDibGQ4VKcBB2iHWuzA71o94BjioW59nO-p5vwdH9tBdRxvD3WD-wIdo5hJ9Sbnv026NBDASHO_aF-EGqVuoQaV9Kpitp35dBjoz1yXkjZymJ_rZ_YSe4-gns37klS_YyIU_0OPm26dEyah6HqFhw8RnB1C8mzOY75aeacdMFOgzYe7EZiQbGShxAvi4k9JgiBLG0dpkZa3u7Q5VPbVJusvcrnAD_r6jUmVhV9uitZhAMa8lNKOdlpTC6tClpIXAHAbFcTSf8xi4cnQXw9eEAcmERhBhU4BS9d25YVmaddTHho_bteVx_86CePy_Y-B0v0muFKC8gOaytqTlUHXC9GgCAdKUsBOrNfrogIVacM1fckQJgoJsMuw5A5Txr0IDxVXkPzvfyPg6ue9jH2LlU7V4x0RmXK5EBAi7Z_pL863OKTujYgJ1WjQvXEmeQaD1ylmoEgKpsg7xYpKSVZP1hWcCh09RGoAPhCjeJBK45ZeobT18IULnUmp_IXPJPr-Uo2rEJAq7yHckfAaCce4anjGIK08o3bjBxFJexdi20HQ6QIdcSgtYBiE29rZwZc5CqBWkD-pm30DnnCWe1ViZYLXUD1iU8qPlfvuJI5SR6PiZke6kdd1ymieFuqB823yM9W-ewfpEikWBANBFN-qGm6I0OHaajhMgDzrsfrw7ncLf_ZUOtSMYW2r4gxHIkpRDUT0n2oR7MPQdKbXq1JQjjj-NK1IbkQh-pqgpLsj-X4gNgvPUvaLaYhixTZEc5_sBdZnj0ULSpjZ-vsiOGxgfL2h5Qiqo3FYdLUMd2qCrUbK6a7-bM6_Zyk-UigAbnmLEE-ZwDkQWztKVrZkDoifl0lam_Sb6AGE2PGGiFJw7Hd35kQ15GzuaNG-uuMXMKdnIghAxlcBTeYL1ldfuyouVks-fkSJiCdDCakUs2X_ainOhZ1E4GQum10CIwEEDTnzlTKceCZ7ZWAuxTraiiIaHPVYgZ1WZCNrQT9dXQutCKjqsr3Dl7VBy0MhhFmKT3bknfdB-pLgnAPCvErMwVZVnued4SGTBuUJpSvFElaZULl0tiZAXjbnkX1wOOviJ9QISlwiUhRVtHD5Q7NoiQxckaEGwU7hw1-9iSMlycGbzOweF6ErHyVvFrMB-iq9QBly222cdzDQNB9pCZBf2T0KH542rAQpMhRCRzLscduQvm6XNsNx4jnq265vgWtzeIp5IobZhmkQxxAYNwga_FTkGgGrif1lwvRKMP808cq4XPT_7wLS-bMYquTDg5_bpYeSBW-2OMjgaL2CWUP7ARPXZwCvnmN0bRREm9E7K49u8Knd1Kam2UzbEII5MbeCviqJSp5skrysfYx3pmRYH6ThYTXc7B62YUvZE_avc_DzZ56bWPHmHSrAux4dqgcS3PFzpEpi0mHVwYzWGb0pZlREawUHDFuiNJK_Y_ztkXXAjC-I01v1PRZOm3SVST6ME8nCdZuwTZGg8ykZBRbBmG2o605sRf_irzOTxZ9E-NIHMO89_mJaSoqY90-4hhWxWvtZkNckAgJNIhOeXqeA0NUKAwcsogNORSbA6BzlMv8GMe8oWNZJ5dSpVrertKnKTlyicqqFb7uMdE1OaQ6yF0pYXl-b4U6wleX5IL32iDHeROofUjtR__qrCFEF8SufZmeqVoWk-EdV9l50aQAST744MpW31MLHCtaCI7PpgrSHKNjkWk1qR6bx4JH6GRa63mAF75QgfPToTkhEJL5PfLfKshccMTocVaAPYrGI7Cw_LeDsC1XxPlExq_ICrB9A_IqRhq7dtV9kc-grA1EwRekPtgyhu9avzSI3DnYKW43yOXsw6lQkB5FJZPsKzQLwA_LOHeL3ZuiK0qcJSJPWDxKuo9MQR4BtPTt1LSc6urboS65E--8diOVQwSPgG-l6_f7kDvN9Nk3-Wu8bn2Gh69eew93mLrQxQqZtNSfBm2OpOaoF4q1B0n_OgKx5NiAgd73nPiwdrvbVm3GSShPm5eX_BhspJH4OAXhRpnpzutZTKXvFzZby5tNWwndad06hFEWXyvTNz-Q4dCJPU2Blch_17h-8D4b5LlRXRhhZ5wmwzlKcYWPyNllzHX0bLHbrSKprs4TjtOB9AiAPsrvskWFJ7zjXboKPSTMI0zeoKkMOC_qsZKeEzqoKfTGi3XUY1mSMXv0SoNA__C95nuNTX34.5a_BhU7-0zgjUUuYZ4zHNQ"

# %% [markdown]
# # Authentication

# %% [markdown]
# ### Google Cloud auth

# %%
# GoogleCloud Authentication
import os
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "C:\\Users\\Rain\\Notebook\\key.json"
print(os.environ["GOOGLE_APPLICATION_CREDENTIALS"])

# %% [markdown]
# ### ChatGPT auth

# %%
## ChatGPT Authentication

# revChatGPT
from revChatGPT.ChatGPT import Chatbot
config={
  "session_token": secret_token,
  "verbose": True
}

# pyChatGPT
# from pyChatGPT import ChatGPT

# %% [markdown]
# # Defining Variables

# %%
warnings.filterwarnings("ignore")
model = whisper.load_model("base")
model.device

# %%
# Google TTS client initialization
import google.cloud.texttospeech as tts
client = tts.TextToSpeechClient()

# %% [markdown]
# # Text to Speech

# %%
# Synth audio from text

def text_to_wav(voice_name: str, text: str):
    language_code = "-".join(voice_name.split("-")[:2])
    text_input = tts.SynthesisInput(text=text)
    voice_params = tts.VoiceSelectionParams(
        # language_code=language_code, name=voice_name
        language_code=language_code, name=voice_name, ssml_gender=tts.SsmlVoiceGender.FEMALE
    )
    audio_config = tts.AudioConfig(audio_encoding=tts.AudioEncoding.LINEAR16)

    response = client.synthesize_speech(
        input=text_input, voice=voice_params, audio_config=audio_config
    )

    filename = f"out.WAV"
    with open(filename, "wb") as out:
        out.write(response.audio_content)
        print(f'Generated speech saved to "{filename}"')

# %% [markdown]
# # Speech to Text>ChatGPT

# %%
def transcribe(audio):

    # load audio and pad/trim it to fit 30 seconds
    audio = whisper.load_audio(audio)
    audio = whisper.pad_or_trim(audio)

    # make log-Mel spectrogram and move to the same device as the model
    mel = whisper.log_mel_spectrogram(audio).to(model.device)

    # detect the spoken language
    _, probs = model.detect_language(mel)

    # decode the audio
    options = whisper.DecodingOptions()
    result = whisper.decode(model, mel, options)
    result_text = result.text

    # Pass the generated text to Audio
    # chatgpt_api = ChatGPT(secret_token)   # pyChatGPT
    # resp = chatgpt_api.send_message(result_text) #pychatGPT
    # out_result = resp['message']
    chatgpt_api = Chatbot(config, conversation_id=None, parent_id=None) #revChat
    resp = chatgpt_api.ask(result_text, conversation_id=None, parent_id=None) #revchat
    print(resp)

    text_to_wav("en-US-Wavenet-C", resp['message'])
    
    import vlc
    # creating a vlc instance
    vlc_instance = vlc.Instance()
    # creating a media player
    player = vlc_instance.media_player_new()

    # creating a media
    media = vlc_instance.media_new("out.WAV")

    # setting media to the player
    player.set_media(media)

    player.audio_set_volume(30)
    player.play()

    out_result = resp['message']
    return [result_text, out_result]

# %% [markdown]
# ### Web UI

# %%
output_1 = gr.Textbox(label="Speech to Text")
output_2 = gr.Textbox(label="ChatGPT Output")


gr.Interface(
    title = 'OpenAI Whisper and ChatGPT ASR Gradio Web UI', 
    fn=transcribe, 
    inputs=[
        gr.inputs.Audio(source="microphone", type="filepath")
    ],

    outputs=[
        output_1,  output_2
    ],
    live=True).launch()

# %%
text_to_wav("en-US-Wavenet-C", "What is the temperature in Sydney?")

# %%
# import vlc
# # creating a vlc instance
# vlc_instance = vlc.Instance()
# # creating a media player
# player = vlc_instance.media_player_new()

# # creating a media
# media = vlc_instance.media_new("out.WAV")

# # setting media to the player
# player.set_media(media)

# player.audio_set_volume(30)
# player.play()
